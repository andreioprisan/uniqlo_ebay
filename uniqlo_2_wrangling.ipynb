{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "date = '7_11'\n",
    "num_scrapes = 3\n",
    "\n",
    "items_df_1 = pd.concat([pd.read_csv('uniqlo/%s_listings_df_%s0.csv'%(date, str(i))) \\\n",
    "                     for i in range(num_scrapes)])\n",
    "items_df_2 = pd.read_csv('uniqlo/8_01_listings_df_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Clean various columns of listings data, cast them into appropriate data types, \n",
    "    and concatenate them appropriately\n",
    "'''\n",
    "def clean_items_df(items_df):\n",
    "    items_df = items_df.drop_duplicates().reset_index(drop = True)\n",
    "    items_df = items_df.iloc[:,2:]\n",
    "    items_df['num_reviews'] = [int(re.sub(\"[^0-9]\", \"\", score)) \\\n",
    "            if score != 'BAD' else None for score in items_df['score']]\n",
    "    items_df['price'] = [float(price[1:].replace(',', '')) for price in items_df['price']]\n",
    "    items_df['shipping'] = [float(re.sub(\"[^0-9.]\", \"\", shipping)) if re.sub(\"[^0-9.]\", \"\", shipping) != '' \\\n",
    "         else 0 for shipping in items_df['shipping']]\n",
    "    items_df['is_auction_item'] = [num_bids != '0' for num_bids in items_df['num_bids']]\n",
    "    items_df['num_bids'] = [int(re.sub(\"[^0-9]\", \"\", num_bids)) for num_bids in items_df['num_bids']]\n",
    "    items_df['date'] = [datetime.strptime(str(date)[:-4], '%b %d, %Y %H:%M:%S') \\\n",
    "                if str(date)[:-4] != '' else None for date in items_df['date']]\n",
    "    return items_df\n",
    "\n",
    "\n",
    "'''\n",
    "    Adjust and add variables (total price, total caps, total chars, is kaws or not, region) \n",
    "    to be included in exploratory data analysis \n",
    "'''\n",
    "def add_variables(items_df):\n",
    "    items_df['total_price'] = items_df['price'] + items_df['shipping']\n",
    "    items_df['total_caps'] = [sum([1 for char in title if char.isupper()]) for title in items_df['title']]\n",
    "    items_df['total_chars'] = [len(title.replace(' ', '')) for title in items_df['title']]\n",
    "    items_df['is_kaws'] = [title.lower().find('kaws') != -1 for title in items_df['title']]\n",
    "    items_df['region'] = [loc.split(', ')[1] if loc.split(', ')[-1] == 'United States' else 'International' \\\n",
    "                          for loc in items_df['location'].astype('str')]\n",
    "    clean_states_dict = dict(zip(['CA', 'MA', 'NY'], ['California', 'Massachusetts', 'New York']))\n",
    "    items_df['region'] = [clean_states_dict[region] if clean_states_dict.get(region) != None \\\n",
    "                          else region for region in items_df['region']]\n",
    "    def parse_str(loc_str):\n",
    "        string = loc_str.split(',')[0]\n",
    "        final_str = string\n",
    "        if string in ['United States of America', 'USA Sportswear', 'East Coast', 'Bend', 'USA']:\n",
    "            final_str = None\n",
    "        elif string == 'NJ':\n",
    "            final_str = 'New Jersey'\n",
    "        elif string == 'miami':\n",
    "            final_str = 'Florida'\n",
    "        elif string == 'CA':\n",
    "            final_str = 'California'\n",
    "        return final_str\n",
    "    \n",
    "    final_strs = [parse_str(loc_str) for loc_str in items_df[items_df.region == 'United States'].location]\n",
    "    items_df.loc[items_df.region == 'United States', 'region'] = final_strs\n",
    "    return items_df\n",
    "    \n",
    "cl_items_df_1 = add_variables(clean_items_df(items_df_1))\n",
    "cl_items_df_2 = add_variables(clean_items_df(items_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Replace missing time values with estimates such that each unknown listing time\n",
    "    (or times) must lie at an equal time duration away from its adjacent listings \n",
    "    (either known or unknown)\n",
    "'''\n",
    "def approx_missing_times(times):\n",
    "    need_to_approx = False\n",
    "    new_times = [None] * len(times)\n",
    "    for i in range(len(times)):\n",
    "        if not pd.isnull(times[i]):\n",
    "            #have nulls yet to be estimated & reached non-null time -> fill in previous null values with bounds\n",
    "            if need_to_approx:\n",
    "                num_approx = i - maxdex_missing \n",
    "                estimates = [times[i] + ((j + 1) * (times[maxdex_date] - times[i]) \\\n",
    "                                           / num_approx) for j in range(num_approx)]\n",
    "                estimates.reverse()\n",
    "                new_times[maxdex_missing : i] = estimates\n",
    "                need_to_approx = False\n",
    "            maxdex_date = i\n",
    "        else:\n",
    "            #found at least one null -> keep track of index and status \n",
    "            if not need_to_approx:\n",
    "                maxdex_missing = i\n",
    "                need_to_approx = True\n",
    "    return [times[i] if not pd.isnull(times[i]) else new_times[i] for i in range(len(times))]\n",
    "\n",
    "\n",
    "cl_items_df_1['date_approx'] = approx_missing_times(cl_items_df_1['date'])\n",
    "cl_items_df_2['date_approx'] = approx_missing_times(cl_items_df_2['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trim listings data to only be shirts sold between 5/1/2020 and 8/1/2020\n",
    "fi_items_1 = cl_items_df_1[(cl_items_df_1['date_approx'] >= datetime(2020, 5, 1)) & \\\n",
    "                        (cl_items_df_1['date_approx'] < datetime(2020, 6, 27))] \n",
    "fi_items_2 = cl_items_df_2[(cl_items_df_2['date_approx'] >= datetime(2020, 6, 27)) & \\\n",
    "              (cl_items_df_2['date_approx'] < datetime(2020, 8, 1))] \n",
    "\n",
    "cl_items_df = pd.concat([fi_items_1, fi_items_2]).reset_index(drop = True).sort_values(by = 'date_approx')\n",
    "cl_items_df['mn_day'] = [trans_time.strftime('%-m/%-d') for trans_time in cl_items_df['date_approx']]\n",
    "cl_items_df['mn_day_date'] = [trans_time.date() for trans_time in cl_items_df['date_approx']]\n",
    "cl_items_df = cl_items_df[cl_items_df.region != None].reset_index(drop = True)\n",
    "\n",
    "cl_items_df.to_excel('final_uniqlo_data.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
